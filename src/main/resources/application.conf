pekko {
    loglevel = "INFO"
    stdout-loglevel = "INFO"
    loggers = ["org.apache.pekko.event.slf4j.Slf4jLogger"]
    logging-filter = "org.apache.pekko.event.slf4j.Slf4jLoggingFilter"
    log-dead-letters = 10
    log-dead-letters-during-shutdown = off
    log-dead-letters = off
    actor {
        provider = cluster
        debug {
            receive = off
            lifecycle = off
            unhandled = off
            autoreceive = off
        }
        allow-java-serialization = off
        serializers {
            proto = "org.apache.pekko.remote.serialization.ProtobufSerializer"
            envelope = "org.interscity.htc.core.serializer.EntityEnvelopeSerializer"
            actor-interaction = "org.interscity.htc.core.serializer.ActorInteractionSerializer"
            jackson-json = "org.apache.pekko.serialization.jackson.JacksonJsonSerializer"
            jackson-cbor = "org.apache.pekko.serialization.jackson.JacksonCborSerializer"
        }
        serialization-bindings {
            "org.interscity.htc.core.entity.event.EntityEnvelopeEvent" = envelope
            "scalapb.GeneratedMessage" = proto
            "org.interscity.htc.core.entity.event.ActorInteractionEvent" = actor-interaction
            "org.interscity.htc.core.entity.event.control.execution.TimeManagerRegisterEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.CreateActorsEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.FinishCreationEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.FinishLoadDataEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.LoadDataCreatorRegisterEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.InitializeEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.LoadDataEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.data.BaseEventData" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.report.RegisterReportersEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.report.ReportEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.LoadDataSourceEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.LoadNextEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.ProcessBatchesEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.control.load.ProcessNextCreateChunk" = jackson-cbor
            "org.interscity.htc.core.entity.event.SpontaneousEvent" = jackson-cbor
            "org.interscity.htc.core.entity.event.FinishEvent" = jackson-cbor
            "org.interscity.htc.core.actor.ActorSerializable" = jackson-cbor

            // Eventos de status do LocalTimeManager - serializa√ß√£o adequada sem Java serialization
            "org.interscity.htc.core.actor.manager.time.RequestStatusEvent" = jackson-cbor
            "org.interscity.htc.core.actor.manager.time.StatusResponseEvent" = jackson-cbor

            "org.interscity.htc.core.entity.actor.properties.Properties" = jackson-cbor
            "org.interscity.htc.core.entity.actor.properties.CreatorProperties" = jackson-cbor
            "org.interscity.htc.core.entity.state.BaseState" = jackson-cbor
            "java.time.LocalDateTime" = jackson-cbor
        }
    }

    persistence {
      journal {
        plugin = "pekko.persistence.cassandra.journal"
        auto-start-journals = ["pekko.persistence.cassandra.journal"]
      }
      snapshot-store {
        plugin = "pekko.persistence.cassandra.snapshot"
        auto-start-snapshot-stores = ["pekko.persistence.cassandra.snapshot"]
      }
      # Desabilitar snapshots autom√°ticos para melhor desempenho
      snapshot-store.local.dir = "disabled"
      # Configurar estrat√©gia de snapshot menos agressiva
      snapshot {
        # Reduzir frequ√™ncia de snapshots autom√°ticos
        auto-snapshot-interval = 1000
        # Manter menos snapshots na mem√≥ria
        max-nr-of-snapshots = 2
      }
    }

    remote {
        artery {
            canonical {
                hostname = ${clustering.ip}
                port = ${clustering.port}
            }
        }
    }

    cluster {
        downing-provider-class = "org.apache.pekko.cluster.sbr.SplitBrainResolverProvider"
        seed-nodes = [
            "pekko://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}
        ]
        sharding {
            passivation {
                strategy = "default-idle-strategy"
                default-idle-strategy {
                  idle-entity.timeout = 1200.minutes
                }
            }
            verbose-debug-logging = off
            waiting-for-state-timeout = 1 minute
            # Desabilitar snapshots no sharding para melhor performance
            remember-entities = false
            snapshot-after = 0
        }
    }

    cluster.bootstrap {
        contact-point-discovery {
            service-name  = "pekko-node"
            port-name     = "management"
            protocol      = "http"
        }
    }

    management {
        http {
            hostname = "0.0.0.0"
            port = ${clustering.management-http-port}
        }
    }

    discovery {
        method = config
    }
}

pekko.persistence.cassandra {
  keyspace-autocreate = true
  tables-autocreate = true

  # Connection settings
  contact-points = ["cassandra:9042"]
  local-datacenter = "datacenter1"

  # Consistency levels for single node
  read-consistency = "LOCAL_ONE"
  write-consistency = "LOCAL_ONE"

  journal {
    keyspace = "htc_persistence"
    max-message-batch-size = 500
    target-partition-size = 1000000
    support-all-persistence-ids = off
    # Single node consistency
    read-consistency = "LOCAL_ONE"
    write-consistency = "LOCAL_ONE"
  }

  snapshot {
    keyspace = "htc_persistence"
    # Single node consistency
    read-consistency = "LOCAL_ONE"
    write-consistency = "LOCAL_ONE"
    # Desabilitar snapshots autom√°ticos para melhor desempenho
    automatic-cleanup = false
    delete-old-snapshots = false
    # Configura√ß√µes de performance
    max-concurrent-reads = 16
    max-concurrent-writes = 16
  }

  query {
    refresh-interval = 1s
    max-buffer-size = 2000
    deserialization-parallelism = 4
    read-consistency = "LOCAL_ONE"
  }

  # Timeout settings for development
  timeouts {
    read = 10s
    write = 10s
    schema-timeout = 30s
  }

  # Connection settings
  connection {
    reconnect-on-init = true
    # Melhorar performance de conex√£o
    compression = "NONE"
    pool-timeout = 5s
  }

  events-by-tag {
    enabled = false
  }

  # Configura√ß√µes de performance adicionais
  performance {
    # Desabilitar snapshots desnecess√°rios
    disable-snapshots = true
    # Otimizar batching
    batch-writes = true
    # Reduzir overhead de metadata
    metadata-table = false
  }

  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 16
      parallelism-factor = 2
      parallelism-max = 64
    }
  }
}

clustering {
    ip = "127.0.0.1"
    ip = ${?CLUSTER_IP}
    port = 1600
    port = ${?CLUSTER_PORT}
    seed-ip = "127.0.0.1"
    seed-ip = ${?CLUSTER_IP}
    seed-ip = ${?SEED_PORT_1600_TCP_ADDR}
    seed-port = 1600
    seed-port = ${?SEED_PORT_1600_TCP_PORT}
    management-http-port = 8558
    management-http-port = ${?MANAGEMENT_HTTP_PORT}
    cluster.name = hyperbolic-time-chamber
}

htc {

    report-manager {
        default-strategy = "json"  # Mudado de cassandra para json
        enabled-strategies = ["csv", "json", "cassandra"]

        csv {
            prefix = "htc_simulation_"
            directory = "/app/hyperbolic-time-chamber/output/reports/csv"
            number-of-instances = 2
            number-of-instances-per-node = 1
            batch-size = 1000  # Menor para evitar perda de eventos
        }

        json {
            prefix = "htc_simulation_"
            directory = "/app/hyperbolic-time-chamber/output/reports/json"
            number-of-instances = 2
            number-of-instances-per-node = 1
            batch-size = 1000  # Menor para evitar perda de eventos
        }

        cassandra {
            hosts = "cassandra:9042"
            keyspace = "htc_reports"
            table = "simulation_reports"
            datacenter = "datacenter1"
            batch-size = 1000
            number-of-instances = 8
            number-of-instances-per-node = 1
        }
    }

    databases {
        cassandra {
            default {
                contact-points = ["cassandra:9042"]
                keyspace = "keyspace_default"
                local-datacenter = "datacenter1"
                credentials {
                    username = "your-username"
                    password = "your-password"
                }
                actor {
                    number-of-instances = 8
                    number-of-instances-per-node = 1
                }
            }
        }
    }

    brokers {
        kafka {
            bootstrap-servers = "localhost:9092"

            consumer {
                group-id-suffix = "htc-group"
                auto-offset-reset = "earliest"
            }
        }
    }

    # üÜï CONFIGURA√á√ÉO DE SIMULA√á√ÉO
    simulation {
        # ID √∫nico da simula√ß√£o (opcional)
        # Se n√£o especificado, ser√° gerado automaticamente
        # Tamb√©m pode ser definido via vari√°vel de ambiente HTC_SIMULATION_ID
        # id = "custom_simulation_001"

        # üé≤ SEED PARA REPRODUTIBILIDADE (opcional)
        # Se n√£o especificado, ser√° baseado no timestamp atual
        # Tamb√©m pode ser definido via vari√°vel de ambiente HTC_RANDOM_SEED
        # random-seed = 12345
        # random-seed = ${?HTC_RANDOM_SEED}
    }
}

datastax-java-driver {
  basic.contact-points = ["cassandra:9042"]
  basic.load-balancing-policy.local-datacenter = "datacenter1"
  basic.request.timeout = 10 seconds
  basic.request.consistency = LOCAL_ONE
  advanced.reconnect-on-init = true
  advanced.connection {
    init-query-timeout = 10 seconds
    set-keyspace-timeout = 10 seconds
  }

  # Otimiza√ß√µes de performance
  advanced.control-connection {
    timeout = 5 seconds
  }

  # Configura√ß√µes de pool de conex√µes otimizadas
  advanced.connection.pool {
    local.size = 4
    remote.size = 2
  }

  profiles {
    pekko-persistence-cassandra-profile {
      basic.request {
        consistency = LOCAL_ONE
        default-idempotence = true
        timeout = 10 seconds
      }
      # Desabilitar features desnecess√°rias
      advanced.continuous-paging.enabled = false
    }
    pekko-persistence-cassandra-snapshot-profile {
      basic.request {
        consistency = LOCAL_ONE
        default-idempotence = true
        timeout = 10 seconds
      }
      # Otimizar snapshots quando necess√°rios
      advanced.continuous-paging.enabled = false
      advanced.prepared-statements.cache.size = 100
    }
  }
}