pekko {
    loglevel = "INFO"
    stdout-loglevel = "INFO"
    loggers = ["org.apache.pekko.event.slf4j.Slf4jLogger"]
    logging-filter = "org.apache.pekko.event.slf4j.Slf4jLoggingFilter"
    actor {
        provider = cluster
        debug {
            receive = on
            lifecycle = on
        }
        serializers {
            jackson-json = "org.apache.pekko.serialization.jackson.JacksonJsonSerializer"
            kryo = "io.altoo.serialization.kryo.pekko.PekkoKryoSerializer"
        }
        serialization-bindings {
            "org.interscity.htc.core.entity.event.BaseEvent" = jackson-json
            "org.interscity.htc.core.entity.event.EntityEnvelopeEvent" = jackson-json
        }
    }

    remote {
        artery {
            canonical {
                hostname = ${clustering.ip}
                port = ${clustering.port}
            }
        }
    }

    cluster {
        downing-provider-class = "org.apache.pekko.cluster.sbr.SplitBrainResolverProvider"
        seed-nodes = [
            "pekko://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}
        ]
        sharding {
            passivation {
                strategy = default-strategy
                default-strategy {
                    idle-entity.timeout = 5.minutes
                }
            }
            verbose-debug-logging = on
            waiting-for-state-timeout = 1 minute
        }
    }

    cluster.bootstrap {
        contact-point-discovery {
            service-name  = "pekko-node"
            port-name     = "management"
            protocol      = "http"
        }
    }

    management {
        http {
            hostname = "0.0.0.0"
            port = 8558
        }
    }

    discovery {
        method = config
    }
}

clustering {
    ip = "127.0.0.1"
    ip = ${?CLUSTER_IP}
    port = 1600
    port = ${?CLUSTER_PORT}
    seed-ip = "127.0.0.1"
    seed-ip = ${?CLUSTER_IP}
    seed-ip = ${?SEED_PORT_1600_TCP_ADDR}
    seed-port = 1600
    seed-port = ${?SEED_PORT_1600_TCP_PORT}
    cluster.name = hyperbolic-time-chamber
}

report-manager {
    enabled-strategies = ["csv", "json", "mongodb", "cassandra", "hbase", "hadoop"]

    hbase {
        zookeeper-quorum = "localhost:2181"
        table-name = "simulation_reports"
    }

    hadoop {
        namenode-uri = "hdfs://localhost:9000"
        directory = "/user/simulation_reports"
    }

    csv {
        directory = "/tmp/reports/csv"
    }

    json {
        directory = "/tmp/reports/json"
    }

    mongodb {
        uri = "mongodb://localhost:27017"
        database = "simulation_reports"
    }

    cassandra {
        contact-points = ["localhost:9042"]
        keyspace = "simulation_reports"
    }
}

databases {
    cassandra {
        default {
            contact-points = ["127.0.0.1:9042"]
            keyspace = "keyspace1"
            local-datacenter = "datacenter1"
            credentials {
                username = "your-username"
                password = "your-password"
            }
        }
    }
}

brokers {
    kafka {
        bootstrap-servers = "localhost:9092"

        consumer {
            group-id-suffix = "htc-group"
            auto-offset-reset = "earliest"
        }
    }
}