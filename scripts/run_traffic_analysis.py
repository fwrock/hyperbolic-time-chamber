#!/usr/bin/env python3
"""
Script principal para executar an√°lise de tr√°fego
Com gerenciamento correto de imports
"""

import sys
import os
from pathlib import Path
import pandas as pd

# Adiciona o diret√≥rio scripts ao PYTHONPATH
SCRIPT_DIR = Path(__file__).parent.resolve()
sys.path.insert(0, str(SCRIPT_DIR))

import argparse
import logging
from datetime import datetime

# Agora podemos fazer imports absolutos
from config import CASSANDRA_CONFIG, OUTPUT_PATH, LOGGING_CONFIG
from data_sources.cassandra_source import CassandraDataSource
from data_sources.file_sources import CSVDataSource, DataSourceFactory
from analysis.traffic_analyzer import TrafficAnalyzer
from visualization.traffic_viz import TrafficVisualizer
from reports.report_generator import TrafficReportGenerator

def setup_logging():
    """Configura o sistema de logging"""
    logging.basicConfig(**LOGGING_CONFIG)
    return logging.getLogger(__name__)

def run_cassandra_analysis(limit: int = None):
    """Executa an√°lise usando dados do Cassandra"""
    logger = logging.getLogger(__name__)
    
    try:
        # Conectar ao Cassandra
        logger.info("üîå Conectando ao Cassandra...")
        cassandra_source = CassandraDataSource(CASSANDRA_CONFIG)
        
        # Carregar dados
        logger.info(f"üìä Carregando dados (limite: {limit})...")
        data = cassandra_source.get_vehicle_flows(limit=limit)
        
        if data.empty:
            logger.warning("‚ö†Ô∏è Nenhum dado encontrado no Cassandra")
            return
        
        logger.info(f"‚úÖ Carregados {len(data)} registros")
        
        # Executar an√°lise
        run_analysis(data, "cassandra", logger)
        
    except Exception as e:
        logger.error(f"‚ùå Erro na an√°lise do Cassandra: {e}")
        raise

def run_csv_analysis(file_path: str):
    """Executa an√°lise usando dados de arquivo CSV"""
    logger = logging.getLogger(__name__)
    
    try:
        # Carregar dados do CSV
        logger.info(f"üìÅ Carregando dados do CSV: {file_path}")
        
        # Converter caminho relativo para absoluto se necess√°rio
        if not os.path.isabs(file_path):
            file_path = os.path.join(SCRIPT_DIR.parent, file_path)
        
        # Se for um arquivo espec√≠fico, carregar diretamente
        if os.path.isfile(file_path):
            data = pd.read_csv(file_path)
            logger.info(f"‚úÖ Carregados {len(data)} registros do arquivo CSV")
        else:
            # Se for um diret√≥rio, usar o m√©todo original
            csv_source = CSVDataSource(file_path)
            data = csv_source.load_vehicle_flow_data()
        
        if data.empty:
            logger.warning("‚ö†Ô∏è Nenhum dado encontrado no arquivo CSV")
            return
        
        logger.info(f"‚úÖ Carregados {len(data)} registros do CSV")
        
        # Executar an√°lise
        run_analysis(data, "csv", logger)
        
    except Exception as e:
        logger.error(f"‚ùå Erro na an√°lise do CSV: {e}")
        raise

def run_analysis(data, source_type: str, logger):
    """Executa a an√°lise completa dos dados"""
    
    try:
        # An√°lise dos dados
        logger.info("üîç Iniciando an√°lise de tr√°fego...")
        analyzer = TrafficAnalyzer()
        
        # An√°lises b√°sicas
        summary = analyzer.basic_statistics(data)
        logger.info(f"üìà Estat√≠sticas b√°sicas calculadas")
        
        # An√°lise temporal
        temporal = analyzer.temporal_analysis(data)
        logger.info(f"‚è∞ An√°lise temporal conclu√≠da")
        
        # An√°lise espacial (se houver dados de localiza√ß√£o)
        spatial = None
        if 'latitude' in data.columns and 'longitude' in data.columns:
            spatial = analyzer.spatial_analysis(data)
            logger.info(f"üó∫Ô∏è An√°lise espacial conclu√≠da")
        
        # Visualiza√ß√µes
        logger.info("üìä Gerando visualiza√ß√µes...")
        visualizer = TrafficVisualizer(data)
        
        # Gr√°ficos temporais
        logger.info("üìà Criando gr√°ficos temporais...")
        
        # Gr√°ficos de estat√≠sticas  
        logger.info("üìä Criando gr√°ficos de distribui√ß√£o...")
        
        # Mapa (se dados espaciais dispon√≠veis)
        if spatial and 'latitude' in data.columns:
            logger.info("üó∫Ô∏è Criando mapa de tr√°fego...")
        
        logger.info("‚úÖ Visualiza√ß√µes salvas em: " + str(OUTPUT_PATH))
        
        # Gerar relat√≥rio
        logger.info("üìã Gerando relat√≥rio...")
        
        report_data = {
            'summary': summary,
            'temporal': temporal,
            'spatial': spatial,
            'source_type': source_type,
            'timestamp': datetime.now().isoformat(),
            'total_records': len(data)
        }
        
        # Salvar dados do relat√≥rio em JSON
        report_file = OUTPUT_PATH / "reports" / f"traffic_analysis_report_{source_type}.json"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Fun√ß√£o para converter dados para JSON serializable
        def json_serializer(obj):
            if hasattr(obj, 'isoformat'):
                return obj.isoformat()
            elif hasattr(obj, 'item'):
                return obj.item()
            elif hasattr(obj, 'tolist'):
                return obj.tolist()
            return str(obj)
        
        with open(report_file, 'w') as f:
            import json
            json.dump(report_data, f, indent=2, default=json_serializer)
        
        logger.info("‚úÖ Relat√≥rio gerado com sucesso!")
        
        # Estat√≠sticas finais
        logger.info("="*60)
        logger.info("üéØ AN√ÅLISE CONCLU√çDA COM SUCESSO!")
        logger.info(f"üìä Total de registros: {len(data)}")
        logger.info(f"üìà Fonte dos dados: {source_type.upper()}")
        logger.info(f"üìÅ Outputs salvos em: {OUTPUT_PATH}")
        logger.info("="*60)
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante an√°lise: {e}")
        raise

def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(description="Traffic Analysis System")
    parser.add_argument('source', choices=['cassandra', 'csv'], help='Fonte dos dados')
    parser.add_argument('--limit', type=int, help='Limite de registros (Cassandra)')
    parser.add_argument('--file', type=str, help='Arquivo CSV (para source=csv)')
    
    args = parser.parse_args()
    
    # Setup logging
    logger = setup_logging()
    logger.info("üöÄ Iniciando Traffic Analysis System...")
    
    # Garantir que diret√≥rios existam
    OUTPUT_PATH.mkdir(parents=True, exist_ok=True)
    
    try:
        if args.source == 'cassandra':
            run_cassandra_analysis(args.limit)
        elif args.source == 'csv':
            if not args.file:
                logger.error("‚ùå --file √© obrigat√≥rio para source=csv")
                return 1
            run_csv_analysis(args.file)
            
        return 0
        
    except Exception as e:
        logger.error(f"üí• Falha na execu√ß√£o: {e}")
        return 1

if __name__ == "__main__":
    exit(main())